{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: appnope==0.1.4 in /Users/alexeydubovitskiy/Desktop/deeppython/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 1)) (0.1.4)\n",
      "Requirement already satisfied: asttokens==3.0.0 in /Users/alexeydubovitskiy/Desktop/deeppython/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 2)) (3.0.0)\n",
      "Requirement already satisfied: attrs==24.2.0 in /Users/alexeydubovitskiy/Desktop/deeppython/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 3)) (24.2.0)\n",
      "Requirement already satisfied: blinker==1.7.0 in /Users/alexeydubovitskiy/Desktop/deeppython/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 4)) (1.7.0)\n",
      "Requirement already satisfied: Brotli==1.1.0 in /Users/alexeydubovitskiy/Desktop/deeppython/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 5)) (1.1.0)\n",
      "Requirement already satisfied: certifi==2024.8.30 in /Users/alexeydubovitskiy/Desktop/deeppython/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 6)) (2024.8.30)\n",
      "Requirement already satisfied: cffi==1.17.1 in /Users/alexeydubovitskiy/Desktop/deeppython/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 7)) (1.17.1)\n",
      "Requirement already satisfied: charset-normalizer==3.4.0 in /Users/alexeydubovitskiy/Desktop/deeppython/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 8)) (3.4.0)\n",
      "Requirement already satisfied: comm==0.2.2 in /Users/alexeydubovitskiy/Desktop/deeppython/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 9)) (0.2.2)\n",
      "Requirement already satisfied: cryptography==44.0.0 in /Users/alexeydubovitskiy/Desktop/deeppython/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 10)) (44.0.0)\n",
      "Requirement already satisfied: debugpy==1.8.9 in /Users/alexeydubovitskiy/Desktop/deeppython/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 11)) (1.8.9)\n",
      "Requirement already satisfied: decorator==5.1.1 in /Users/alexeydubovitskiy/Desktop/deeppython/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 12)) (5.1.1)\n",
      "Requirement already satisfied: et_xmlfile==2.0.0 in /Users/alexeydubovitskiy/Desktop/deeppython/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 13)) (2.0.0)\n",
      "Requirement already satisfied: executing==2.1.0 in /Users/alexeydubovitskiy/Desktop/deeppython/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 14)) (2.1.0)\n",
      "Requirement already satisfied: fake-useragent==2.0.3 in /Users/alexeydubovitskiy/Desktop/deeppython/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 15)) (2.0.3)\n",
      "Requirement already satisfied: h11==0.14.0 in /Users/alexeydubovitskiy/Desktop/deeppython/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 16)) (0.14.0)\n",
      "Requirement already satisfied: h2==4.1.0 in /Users/alexeydubovitskiy/Desktop/deeppython/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 17)) (4.1.0)\n",
      "Requirement already satisfied: hpack==4.0.0 in /Users/alexeydubovitskiy/Desktop/deeppython/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 18)) (4.0.0)\n",
      "Requirement already satisfied: hyperframe==6.0.1 in /Users/alexeydubovitskiy/Desktop/deeppython/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 19)) (6.0.1)\n",
      "Requirement already satisfied: idna==3.10 in /Users/alexeydubovitskiy/Desktop/deeppython/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 20)) (3.10)\n",
      "Requirement already satisfied: ipykernel==6.29.5 in /Users/alexeydubovitskiy/Desktop/deeppython/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 21)) (6.29.5)\n",
      "Requirement already satisfied: ipython==8.30.0 in /Users/alexeydubovitskiy/Desktop/deeppython/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 22)) (8.30.0)\n",
      "Requirement already satisfied: jedi==0.19.2 in /Users/alexeydubovitskiy/Desktop/deeppython/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 23)) (0.19.2)\n",
      "Requirement already satisfied: jupyter_client==8.6.3 in /Users/alexeydubovitskiy/Desktop/deeppython/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 24)) (8.6.3)\n",
      "Requirement already satisfied: jupyter_core==5.7.2 in /Users/alexeydubovitskiy/Desktop/deeppython/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 25)) (5.7.2)\n",
      "Requirement already satisfied: kaitaistruct==0.10 in /Users/alexeydubovitskiy/Desktop/deeppython/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 26)) (0.10)\n",
      "Requirement already satisfied: matplotlib-inline==0.1.7 in /Users/alexeydubovitskiy/Desktop/deeppython/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 27)) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio==1.6.0 in /Users/alexeydubovitskiy/Desktop/deeppython/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 28)) (1.6.0)\n",
      "Requirement already satisfied: numpy==2.2.0 in /Users/alexeydubovitskiy/Desktop/deeppython/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 29)) (2.2.0)\n",
      "Requirement already satisfied: openpyxl==3.1.5 in /Users/alexeydubovitskiy/Desktop/deeppython/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 30)) (3.1.5)\n",
      "Requirement already satisfied: outcome==1.3.0.post0 in /Users/alexeydubovitskiy/Desktop/deeppython/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 31)) (1.3.0.post0)\n",
      "Requirement already satisfied: packaging==24.2 in /Users/alexeydubovitskiy/Desktop/deeppython/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 32)) (24.2)\n",
      "Requirement already satisfied: pandas==2.2.3 in /Users/alexeydubovitskiy/Desktop/deeppython/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 33)) (2.2.3)\n",
      "Requirement already satisfied: parso==0.8.4 in /Users/alexeydubovitskiy/Desktop/deeppython/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 34)) (0.8.4)\n",
      "Requirement already satisfied: pexpect==4.9.0 in /Users/alexeydubovitskiy/Desktop/deeppython/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 35)) (4.9.0)\n",
      "Requirement already satisfied: platformdirs==4.3.6 in /Users/alexeydubovitskiy/Desktop/deeppython/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 36)) (4.3.6)\n",
      "Requirement already satisfied: prompt_toolkit==3.0.48 in /Users/alexeydubovitskiy/Desktop/deeppython/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 37)) (3.0.48)\n",
      "Requirement already satisfied: psutil==6.1.0 in /Users/alexeydubovitskiy/Desktop/deeppython/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 38)) (6.1.0)\n",
      "Requirement already satisfied: ptyprocess==0.7.0 in /Users/alexeydubovitskiy/Desktop/deeppython/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 39)) (0.7.0)\n",
      "Requirement already satisfied: pure_eval==0.2.3 in /Users/alexeydubovitskiy/Desktop/deeppython/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 40)) (0.2.3)\n",
      "Requirement already satisfied: pyasn1==0.6.1 in /Users/alexeydubovitskiy/Desktop/deeppython/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 41)) (0.6.1)\n",
      "Requirement already satisfied: pycparser==2.22 in /Users/alexeydubovitskiy/Desktop/deeppython/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 42)) (2.22)\n",
      "Requirement already satisfied: Pygments==2.18.0 in /Users/alexeydubovitskiy/Desktop/deeppython/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 43)) (2.18.0)\n",
      "Requirement already satisfied: pyOpenSSL==24.3.0 in /Users/alexeydubovitskiy/Desktop/deeppython/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 44)) (24.3.0)\n",
      "Requirement already satisfied: pyparsing==3.2.0 in /Users/alexeydubovitskiy/Desktop/deeppython/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 45)) (3.2.0)\n",
      "Requirement already satisfied: PySocks==1.7.1 in /Users/alexeydubovitskiy/Desktop/deeppython/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 46)) (1.7.1)\n",
      "Requirement already satisfied: python-dateutil==2.9.0.post0 in /Users/alexeydubovitskiy/Desktop/deeppython/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 47)) (2.9.0.post0)\n",
      "Requirement already satisfied: python-dotenv==1.0.1 in /Users/alexeydubovitskiy/Desktop/deeppython/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 48)) (1.0.1)\n",
      "Requirement already satisfied: pytz==2024.2 in /Users/alexeydubovitskiy/Desktop/deeppython/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 49)) (2024.2)\n",
      "Requirement already satisfied: pyzmq==26.2.0 in /Users/alexeydubovitskiy/Desktop/deeppython/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 50)) (26.2.0)\n",
      "Requirement already satisfied: requests==2.32.3 in /Users/alexeydubovitskiy/Desktop/deeppython/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 51)) (2.32.3)\n",
      "Requirement already satisfied: selenium==4.27.1 in /Users/alexeydubovitskiy/Desktop/deeppython/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 52)) (4.27.1)\n",
      "Requirement already satisfied: selenium-wire==5.1.0 in /Users/alexeydubovitskiy/Desktop/deeppython/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 53)) (5.1.0)\n",
      "Requirement already satisfied: setuptools==75.6.0 in /Users/alexeydubovitskiy/Desktop/deeppython/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 54)) (75.6.0)\n",
      "Requirement already satisfied: six==1.17.0 in /Users/alexeydubovitskiy/Desktop/deeppython/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 55)) (1.17.0)\n",
      "Requirement already satisfied: sniffio==1.3.1 in /Users/alexeydubovitskiy/Desktop/deeppython/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 56)) (1.3.1)\n",
      "Requirement already satisfied: sortedcontainers==2.4.0 in /Users/alexeydubovitskiy/Desktop/deeppython/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 57)) (2.4.0)\n",
      "Requirement already satisfied: stack-data==0.6.3 in /Users/alexeydubovitskiy/Desktop/deeppython/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 58)) (0.6.3)\n",
      "Requirement already satisfied: tornado==6.4.2 in /Users/alexeydubovitskiy/Desktop/deeppython/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 59)) (6.4.2)\n",
      "Requirement already satisfied: traitlets==5.14.3 in /Users/alexeydubovitskiy/Desktop/deeppython/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 60)) (5.14.3)\n",
      "Requirement already satisfied: trio==0.27.0 in /Users/alexeydubovitskiy/Desktop/deeppython/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 61)) (0.27.0)\n",
      "Requirement already satisfied: trio-websocket==0.11.1 in /Users/alexeydubovitskiy/Desktop/deeppython/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 62)) (0.11.1)\n",
      "Requirement already satisfied: typing_extensions==4.12.2 in /Users/alexeydubovitskiy/Desktop/deeppython/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 63)) (4.12.2)\n",
      "Requirement already satisfied: tzdata==2024.2 in /Users/alexeydubovitskiy/Desktop/deeppython/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 64)) (2024.2)\n",
      "Requirement already satisfied: ua-parser==1.0.0 in /Users/alexeydubovitskiy/Desktop/deeppython/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 65)) (1.0.0)\n",
      "Requirement already satisfied: ua-parser-builtins==0.18.0.post1 in /Users/alexeydubovitskiy/Desktop/deeppython/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 66)) (0.18.0.post1)\n",
      "Requirement already satisfied: urllib3==2.2.3 in /Users/alexeydubovitskiy/Desktop/deeppython/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 67)) (2.2.3)\n",
      "Requirement already satisfied: user-agents==2.2.0 in /Users/alexeydubovitskiy/Desktop/deeppython/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 68)) (2.2.0)\n",
      "Requirement already satisfied: wcwidth==0.2.13 in /Users/alexeydubovitskiy/Desktop/deeppython/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 69)) (0.2.13)\n",
      "Requirement already satisfied: webdriver-manager==4.0.2 in /Users/alexeydubovitskiy/Desktop/deeppython/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 70)) (4.0.2)\n",
      "Requirement already satisfied: websocket-client==1.8.0 in /Users/alexeydubovitskiy/Desktop/deeppython/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 71)) (1.8.0)\n",
      "Requirement already satisfied: wsproto==1.2.0 in /Users/alexeydubovitskiy/Desktop/deeppython/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 72)) (1.2.0)\n",
      "Requirement already satisfied: zstandard==0.23.0 in /Users/alexeydubovitskiy/Desktop/deeppython/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 73)) (0.23.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Selenium**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Введение***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Что такое Selenium**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы рассматриваем Selenium WebDriver, но там еще есть Selenium IDE и Selenium Grid, но они нам не интересны.\n",
    "\n",
    "Selenium WebDriver — инструмент для автоматизации действий веб-браузера. В большинстве случаев используется для тестирования Web-приложений, но этим не ограничивается. В частности, он может быть использован для решения задач администрирования сайта или регулярного получения данных с различных сайтов (парсинг)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Для чего нужен selenium**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У selenium есть несколько применений:\n",
    "- Автоматизация тестирования веб-приложений\n",
    "- Парсинг данных с сайтов\n",
    "- Мониторинг и проверка работоспособности сайтов\n",
    "- Выполнение повторяющихся задач в браузере"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Основные преимущества selenium**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "К основым преимуществам selenium можно отнести:\n",
    "\n",
    "- Открытый исходный код и большая база пользоваетелй (например у PlayWright документация не такая полная, тк он более молодой)\n",
    "- Поддержка различных браузеров и платформ\n",
    "- Расширяемость и интеграция с другими инструментами\n",
    "- Поддержка параллельного выполнения тестов\n",
    "\n",
    "В целом selenium - это мощный инструмент как для тестирования (основная идея вообще-то тестирование), так и для парсинга данных. Он позволяет закрыть почти все потребности разработчика"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Установка***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Для начала нам нужно установить selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вообще в документации написано, что можно установить PyPI архив и устанавливать командой\n",
    "```bash\n",
    "python setup.py install\n",
    "```\n",
    "\n",
    "Но это какой-то кринж, мы должны уметь работаь с виртуальным окружением"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На этом единсвтенном пункте установка заканчивается. Перейдем к базовым примерам использования"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Базовое использование***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала, чтобы понять с чем мы вообще работаем и перейти к более сложным примерам, разберем пример из официальной документации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Web form\n",
      "Text: Received!\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "driver = webdriver.Chrome()                                                 # Создаем и начинаем сессию браузера\n",
    "\n",
    "driver.get(\"https://www.selenium.dev/selenium/web/web-form.html\")           # Переходим на страницу\n",
    "\n",
    "title = driver.title                                                        # Получаем заголовок страницы\n",
    "\n",
    "driver.implicitly_wait(0.5)                                                 # Ждем 0.5 секунды\n",
    "\n",
    "text_box = driver.find_element(by=By.NAME, value=\"my-text\")                 # Находим текстовое поле по имени\n",
    "submit_button = driver.find_element(by=By.CSS_SELECTOR, value=\"button\")     # Находим кнопку по CSS-селектору\n",
    "\n",
    "\n",
    "text_box.send_keys(\"Selenium\")                                              # Вводим текст в текстовое поле\n",
    "submit_button.click()                                                       # Нажимаем на кнопку, которую нашли\n",
    "                                                                            \n",
    "                                                                            # Тут появляется новая страничка с сообщением\n",
    "\n",
    "message = driver.find_element(by=By.ID, value=\"message\")                    # Находим элемент с сообщением по ID\n",
    "text = message.text                                                         # Получаем текст сообщения\n",
    "\n",
    "driver.quit()                                                               # Закрываем сессию браузера\n",
    "\n",
    "print(f\"Title: {title}\\nText: {text}\")                                      # Выводим заголовок и текст сообщения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь разберем этот пример чуть более подробно.\n",
    "\n",
    "1) Сначала мы создаем сессию браузера.\n",
    "\n",
    "    Там есть куча параметров которые можно передавать в сессию браузера. Я расскажу про те, что мне показались наиболее важными, потому что расписывать про все можно вечно\n",
    "\n",
    "    - ***browserVersion*** нужна для того чтобы установить версию браузера, которую мы хотим запустить (удивительное совпадение названия и смысла)\n",
    "    - ***pageLoadStrategy*** тут есть три опции:\\\n",
    "    \\\n",
    "            *normal* – используется по умолчанию и ждет пока сайт полностью загрузится\\\n",
    "            \\\n",
    "            *eager* – позволяет дожидаться только загрузки DOM дерева, при этом картинки всякие могут еще быть не загружены\\\n",
    "            \\\n",
    "            *none* – сессия ждет пока загрузится только главная страница\n",
    "    \n",
    "    - ***timeouts*** тут опять есть несколько опций:\\\n",
    "    \\\n",
    "            *script* – устанавливает максимальное время отработки скрипта (по дефолту стоит 30 000)\\\n",
    "            \\\n",
    "            *pageLoad* – устанавливает максимальное время ожидание загрузки страницы (по дефолту 300 000)\\\n",
    "            \\\n",
    "            *implicit* – устанавливает время ожидания определения местоположения элемента при поиске (по дефолту 0)\n",
    "    \n",
    "    - ***proxy*** позовляет настроить прокси для запросов между клиентом и сервером."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Далее два шага, понятные без объяснения\n",
    "\n",
    "3. Действительно интересным является ***implicity_wait***\\\n",
    "        Правильный способ синхронизорвать браузер и скрипт - это достаточно трудная задача в selenium, поэтому тут используется простой подход, который не является самым лучшим, но досаточен для примера. Мы используем это для того, чтобы точно дождаться прогрузки всех элементов страницы до того, как мы попытаемся их найти."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Следуюшая ключевая чать кода – это метод ***find_element***\n",
    "\n",
    "    Вообще крутой метод, позволяющий находить любой элемент по любому признаку на странице. Тут можно остановиться и посмотерть подробнее.\n",
    "\n",
    "    ```python\n",
    "    driver.find_element()- находит просто первый попавшийся элемент из DOM, который подходит под переданные параметры. Именно такой подход показан в примере.\n",
    "    ```\n",
    "\n",
    "    Далее рассмотрим использование **find_element** на примере:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "<ol id=\"FCS\">\n",
    " <li class=\"AMI\">…\n",
    " <li class=\"SE\">…\n",
    " <li class=\"EDS\"><span>ЭАД это фкн</span>…\n",
    "</ol>\n",
    "<ul id=\"FES\">\n",
    "  <li class=\"Economics\">…\n",
    "  <li class=\"stat\">…\n",
    "  <li class=\"EDS\"><span>ЭАД это фэн</span>…\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмем вот такой примерчик"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тогда чтобы достать элемент с CLASS_NAME EDS из второй части, мы можем уточнить где мы ищем до поиска элемента EDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "faculty = driver.find_element(By.ID, \"FES\")\n",
    "program = fruits.find_element(By.CLASS_NAME,\"EDS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но такой подход может быть не оптимальным, потому что мы делаем два запроса к браузеру. Надо научиться делать это за 1 запрос. В таком случае нам поможет CSS селектор. Тут все просто"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "program = driver.find_element(By.CSS_SELECTOR,\"#FES .EDS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Еще одна ключевая вещь в этом примере – ***send_keys*** и ***click***.\n",
    "\n",
    "***send_keys*** – заполнение изменяемых полей, например текстовых. Тут вроде бы все понятно должно быть. Сопровождается еще одним методом ***clear***, который позволяет очищать те же поля.\n",
    "\n",
    "***click*** – очевидно что кликает на любой элемент. Примечательно, что кликает именно в центр элемента. Если центра элемента чем-то перекрыт, то возвращает ошибку."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ну и последнее, что осталось - это метод ***quit***, который завершает процесс драйвера и закрывает браузер."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **🎉Ура, мы закончили разбираться с базовым использованием silenium🎉**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Теперь разберем более осмысленный пример**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Мы уже научились базово пользоваться selenium, поэтому надо посмотереть а востребованно ли вообще умение парсить сайты на рынке. Для этого мы хотим распарсить сайт hh.ru на наличие подходящих нам вакансий\n",
    "\n",
    "## Что нам для этого понадобиться?\n",
    "- Нужно узнать как ожидать подгрузки элемента на странице\n",
    "- Что делать со всплывающими окнами на экране"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Во-первых, разберемся с тем, как нам ожидать загрузки конкретного элемента на странице\n",
    "\n",
    "В первом примере мы уже сталкивались с **implicitly_wait**. Основная проблема такого метода, что он устанавливает глобальное время для ожадание всех элементов на странице. Важно отметить, что установка большого времени ожидания не обязаотельно будет увеличивать время работы скрипта, так он будет продолжать работу сразу после того, как нужный элемент подгузиться. Если за отведенное время ничего не появится, то приложение закончит работу с ошибкой.\n",
    "\n",
    "Еще один вариант – **explicit waits**. Это совего рода цикл, в котром драйвер спрашивает у сайта о наличии какого-то конкретного элемента, если элемент появился - цикл заканчивается, в противном случае, по истечении времени вернется ошибка **timeout error**. \n",
    "Основные преимущества такого подхода:\n",
    "- поддерживаются ***expected conditions***\n",
    "- более гибкая настройка времени ожидания для каждого элемента\n",
    "\n",
    "Важно помнить, что ***нельзя*** совмещать **implicit wait** и **explicit waits**. Их использование в одном коде может привести к неопределенному времени ожидания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Что такое ***expected conditions***?\n",
    "\n",
    "Это очень удобная штука, которая позволяет ожидать почти все элементы, которые встречаются на сайтах. Вместо того, чтобы прописывать все в лямбда функциях для explicit wait\n",
    "\n",
    "```python\n",
    "wait = WebDriverWait(driver, timeout=2)\n",
    "wait.until(lambda d : revealed.is_displayed())\n",
    "```\n",
    "\n",
    "можно писать \n",
    "\n",
    "```python\n",
    "WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.CLASS_NAME, 'bloko-modal-close-button')))\n",
    "```\n",
    "\n",
    "[Все функции можно посмотреть тут](https://www.selenium.dev/selenium/docs/api/py/webdriver_support/selenium.webdriver.support.expected_conditions.html)\n",
    "\n",
    "А мы рассмотрим основные:\n",
    "- **alert_is_present()** хорошая штука чтобы отслеживать появление JS алертов\n",
    "- **presence_of_element_located(locator)** позволяет проверить что элемент находится в DOM страницы => его можно спарсить\n",
    "- **visibility_of(element)** проверяет что элемент отображен на экране"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Еще одна проблема - всплывающие окна\n",
    "\n",
    "К этой проблема относиться окно принятия cookie на сайте, которое часто всплывает на весь экран, и пока пользователь не примет или не закроет это окно, он не может пользоваться сайтом.\n",
    "\n",
    "Оказывается что это не такая уж и большая проблема, потому что мы можем просто закинуть **explicit wait** в try и таким образом, если окошко появится, то найти кнопку принятия/закрытия и нажать на нее, а если окна не будет, то мы просто продолжим работу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Python-разработчик (парсинг)\n",
      "Salary: 70 000 – 150 000 ₽ на руки\n",
      "Опыт 1-3 года\n",
      "Можно удалённо\n",
      "\n",
      "Title: Python-разработчик (парсинг)\n",
      "Salary: 70 000 – 150 000 ₽ на руки\n",
      "Опыт 1-3 года\n",
      "Можно удалённо\n",
      "\n",
      "Title: Младший специалист отдела разработки (Python) / Специалист по парсингу данных\n",
      "Salary: от 70 000 ₽ на руки\n",
      "Опыт 1-3 года\n",
      "Можно удалённо\n",
      "\n",
      "Title: Senior Python Developer (Парсинг)\n",
      "Salary: Опыт 3-6 лет\n",
      "Можно удалённо\n",
      "\n",
      "Title: Веб-разработчик WordPress / Парсинг\n",
      "Salary: 150 000 – 250 000 ₽ на руки\n",
      "Опыт 1-3 года\n",
      "\n",
      "Title: Веб-разработчик WordPress / Парсинг / SEO\n",
      "Salary: 120 000 – 250 000 ₽ до вычета налогов\n",
      "Без опыта\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "try:\n",
    "    driver.get('https://hh.ru/')    # Открываем страницу\n",
    "    \n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.NAME, 'text')))  # Ждем, пока не появится поле для ввода текста\n",
    "\n",
    "    search_box = driver.find_element(By.NAME, 'text')   # Находим поле для ввода текста\n",
    "    search_box.send_keys('Python парсинг')              # Вводим текст\n",
    "    search_box.send_keys(Keys.RETURN)                   # Нажимаем Enter\n",
    "\n",
    "    try:    # Проверяем, появилось ли всплывающее окно\n",
    "        WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.CLASS_NAME, 'bloko-modal-close-button'))) # Ждем, пока не появится кнопка закрытия\n",
    "        close_button = driver.find_element(By.CLASS_NAME, 'bloko-modal-close-button')                               # Находим кнопку закрытия\n",
    "        close_button.click()                                                                                        # Нажимаем на кнопку закрытия\n",
    "    except Exception:   # Если всплывающее окно не появилось\n",
    "        print(\"Всплывающего окна нет\")\n",
    "\n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, 'vacancy-serp-content')))    # Ждем, пока не появится блок с вакансиями\n",
    "\n",
    "    jobs = driver.find_elements(By.CLASS_NAME, 'magritte-redesign')   # Находим все вакансии\n",
    "\n",
    "    for job in jobs:    # Перебираем все вакансии\n",
    "        try:\n",
    "            title_element = job.find_element(By.CSS_SELECTOR, 'span[data-qa=\"serp-item__title-text\"]')  # Находим элемент с заголовком\n",
    "            title = title_element.text  # Получаем текст заголовка\n",
    "\n",
    "            if \"парсинг\" in title.lower() or \"parsing\" in title.lower():    # Проверяем, есть ли в заголовке слово \"парсинг\" или \"parsing\"\n",
    "                try:\n",
    "                    salary_element = job.find_element(By.CSS_SELECTOR, '[class*=\"magritte-text__pbpft_3-0-18\"]')    # Находим элемент с зарплатой\n",
    "                    salary = salary_element.text    # Получаем текст зарплаты\n",
    "                except Exception:   # Если зарплата не указана в блоке, который мы нашли\n",
    "                    try:\n",
    "                        salary_element = job.find_element(By.CSS_SELECTOR, '[class*=\"compensation-labels\"]')       # Находим другой возможный элемент с зарплатой\n",
    "                        salary = salary_element.text    \n",
    "                    except Exception:\n",
    "                        salary = \"Зп не указана\"   # Если зарплата не указана\n",
    "\n",
    "                print(f\"Название: {title}\\nЗп: {salary}\\n\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка парсинга: {e}\")\n",
    "\n",
    "finally:\n",
    "    driver.quit()   # Закрываем сессию браузера"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом мы получили базовый парсер вакансий с сайта hh.ru. **Но** мы парсим только одну страничку. А что делать с кучей вакансий, которые не поместились на первую страничку?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Научимся переключаться между страничками\n",
    "\n",
    "Для этого нам надо понять что такое **execute_script**\n",
    "\n",
    "Вообще эта штука позволяет выполнять JS скрипты внутри открытого окна. Нам это позволяет прокручивать страничку и вести себя как обычный юзер. Эта штука может быть полезна, например, если сайт представляет из себя новостную ленту, которая подгружается, когда пользователь скролит ее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***driver.maximize_window()*** полезная штука, чтобы не было пробелем с поиском элементов. Бывает такое, что страничка имеет несколько видов для разныз устройств (да почти всегда так), поэтому если открывать не в полном размере, то она будет свернута под телефон"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Парсим страницу: 1\n",
      "\n",
      "                    ======================================================================\n",
      "                    Название: Python-разработчик (парсинг)\n",
      "                    Зп: 70 000 – 150 000 ₽ на руки\n",
      "Опыт 1-3 года\n",
      "Можно удалённо\n",
      "                    Компания: ООО Аптрейд\n",
      "                    Локация: \n",
      "                    Опыт: Опыт не указан\n",
      "                    URL: https://hh.ru/vacancy/112984894?query=Python&hhtmFrom=vacancy_search_list\n",
      "                    ======================================================================\n",
      "                    \n",
      "\n",
      "Парсим страницу: 2\n",
      "\n",
      "                    ======================================================================\n",
      "                    Название: Младший специалист отдела разработки (Python) / Специалист по парсингу данных\n",
      "                    Зп: от 70 000 ₽ на руки\n",
      "Опыт 1-3 года\n",
      "Можно удалённо\n",
      "                    Компания: MillionAgents\n",
      "                    Локация: \n",
      "                    Опыт: Опыт не указан\n",
      "                    URL: https://hh.ru/vacancy/111896085?query=Python&hhtmFrom=vacancy_search_list\n",
      "                    ======================================================================\n",
      "                    \n",
      "\n",
      "                    ======================================================================\n",
      "                    Название: Senior Python Developer (Парсинг)\n",
      "                    Зп: Опыт 3-6 лет\n",
      "Можно удалённо\n",
      "                    Компания: ООО РУМАТИКА\n",
      "                    Локация: \n",
      "                    Опыт: Опыт не указан\n",
      "                    URL: https://hh.ru/vacancy/112071875?query=Python&hhtmFrom=vacancy_search_list\n",
      "                    ======================================================================\n",
      "                    \n",
      "\n",
      "Парсим страницу: 3\n",
      "\n",
      "Парсим страницу: 4\n",
      "\n",
      "Парсим страницу: 5\n",
      "\n",
      "Парсим страницу: 6\n",
      "\n",
      "Парсим страницу: 7\n",
      "\n",
      "Парсим страницу: 8\n",
      "\n",
      "Парсим страницу: 9\n",
      "\n",
      "                    ======================================================================\n",
      "                    Название: Python Web Scraper / Web Parsing Developer\n",
      "                    Зп: 170 000 – 275 000 ₽ на руки\n",
      "Опыт 3-6 лет\n",
      "Можно удалённо\n",
      "                    Компания: ИП Рязанова Анастасия Валерьевна\n",
      "                    Локация: \n",
      "                    Опыт: Опыт не указан\n",
      "                    URL: https://hh.ru/vacancy/112237689?query=Python&hhtmFrom=vacancy_search_list\n",
      "                    ======================================================================\n",
      "                    \n",
      "\n",
      "Парсим страницу: 10\n",
      "\n",
      "Парсим страницу: 11\n",
      "\n",
      "Парсим страницу: 12\n",
      "\n",
      "Парсим страницу: 13\n",
      "\n",
      "Парсим страницу: 14\n",
      "\n",
      "Парсим страницу: 15\n",
      "\n",
      "Парсим страницу: 16\n",
      "\n",
      "Парсим страницу: 17\n",
      "\n",
      "Парсим страницу: 18\n",
      "\n",
      "Парсим страницу: 19\n",
      "\n",
      "Парсим страницу: 20\n",
      "\n",
      "Парсим страницу: 21\n",
      "\n",
      "Парсим страницу: 22\n",
      "\n",
      "Парсим страницу: 23\n",
      "\n",
      "Парсим страницу: 24\n",
      "\n",
      "Парсим страницу: 25\n",
      "\n",
      "Парсим страницу: 26\n",
      "\n",
      "Парсим страницу: 27\n",
      "\n",
      "Парсим страницу: 28\n",
      "\n",
      "                    ======================================================================\n",
      "                    Название: Веб-разработчик WordPress / Парсинг\n",
      "                    Зп: 150 000 – 250 000 ₽ на руки\n",
      "Опыт 1-3 года\n",
      "                    Компания: ООО Юниксбот\n",
      "                    Локация: \n",
      "                    Опыт: Опыт не указан\n",
      "                    URL: https://hh.ru/vacancy/112465930?query=Python&hhtmFrom=vacancy_search_list\n",
      "                    ======================================================================\n",
      "                    \n",
      "\n",
      "Парсим страницу: 29\n",
      "\n",
      "Парсим страницу: 30\n",
      "\n",
      "Парсим страницу: 31\n",
      "\n",
      "Парсим страницу: 32\n",
      "\n",
      "Парсим страницу: 33\n",
      "\n",
      "Парсим страницу: 34\n",
      "\n",
      "Парсим страницу: 35\n",
      "\n",
      "Парсим страницу: 36\n",
      "\n",
      "Больше нет страниц чтобы парсить: Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\"span[data-qa=\"pager-page\"]\"}\n",
      "  (Session info: chrome=131.0.6778.109); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\n",
      "Stacktrace:\n",
      "0   chromedriver                        0x0000000104c6baf0 cxxbridge1$str$ptr + 3651580\n",
      "1   chromedriver                        0x0000000104c64340 cxxbridge1$str$ptr + 3620940\n",
      "2   chromedriver                        0x00000001046cc4b4 cxxbridge1$string$len + 89224\n",
      "3   chromedriver                        0x0000000104710898 cxxbridge1$string$len + 368748\n",
      "4   chromedriver                        0x000000010474a0fc cxxbridge1$string$len + 604368\n",
      "5   chromedriver                        0x00000001047050b0 cxxbridge1$string$len + 321668\n",
      "6   chromedriver                        0x0000000104705d00 cxxbridge1$string$len + 324820\n",
      "7   chromedriver                        0x0000000104c36e34 cxxbridge1$str$ptr + 3435328\n",
      "8   chromedriver                        0x0000000104c3a14c cxxbridge1$str$ptr + 3448408\n",
      "9   chromedriver                        0x0000000104c1e1a8 cxxbridge1$str$ptr + 3333812\n",
      "10  chromedriver                        0x0000000104c3aa0c cxxbridge1$str$ptr + 3450648\n",
      "11  chromedriver                        0x0000000104c0f9b4 cxxbridge1$str$ptr + 3274432\n",
      "12  chromedriver                        0x0000000104c55120 cxxbridge1$str$ptr + 3558956\n",
      "13  chromedriver                        0x0000000104c5529c cxxbridge1$str$ptr + 3559336\n",
      "14  chromedriver                        0x0000000104c63fb4 cxxbridge1$str$ptr + 3620032\n",
      "15  libsystem_pthread.dylib             0x0000000194ccb2e4 _pthread_start + 136\n",
      "16  libsystem_pthread.dylib             0x0000000194cc60fc thread_start + 8\n",
      "\n",
      "\n",
      "Информация была сохранения в python_jobs_20241211_224609.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import csv\n",
    "import random\n",
    "from datetime import datetime\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "\n",
    "# хочется сохранить данные в файл, чтобы потом можно было их читать\n",
    "def save_to_csv(data, filename):\n",
    "    with open(filename, 'a', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(data)\n",
    "\n",
    "# функция для парсинга страницы\n",
    "def parse_page(driver, csv_filename):\n",
    "    # В целом тут все как в прошлом примере, только теперь мы сохраняем данные в файл и их больше\n",
    "    jobs = driver.find_elements(By.CLASS_NAME, 'magritte-redesign')\n",
    "    \n",
    "    for job in jobs:\n",
    "        try:\n",
    "            title_element = job.find_element(By.CSS_SELECTOR, 'span[data-qa=\"serp-item__title-text\"]')\n",
    "            title = title_element.text\n",
    "\n",
    "            if \"парсинг\" in title.lower() or \"parsing\" in title.lower():\n",
    "                try:\n",
    "                    salary_element = job.find_element(By.CSS_SELECTOR, '[class*=\"magritte-text__pbpft_3-0-18\"]')\n",
    "                    salary = salary_element.text\n",
    "                except Exception:\n",
    "                    try:\n",
    "                        salary_element = job.find_element(By.CSS_SELECTOR, '[class*=\"compensation-labels\"]')\n",
    "                        salary = salary_element.text\n",
    "                    except Exception:\n",
    "                        salary = \"Зп не указана\"\n",
    "\n",
    "                try:\n",
    "                    company_element = job.find_element(By.CSS_SELECTOR, '[data-qa=\"vacancy-serp__vacancy-employer\"]')\n",
    "                    company = company_element.text\n",
    "                except Exception:\n",
    "                    company = \"Компания не указана\"\n",
    "\n",
    "                try:\n",
    "                    location_element = job.find_element(By.CSS_SELECTOR, '[data-qa=\"vacancy-serp__vacancy-address\"]')\n",
    "                    location = location_element.text\n",
    "                except Exception:\n",
    "                    location = \"Локация не указана\"\n",
    "\n",
    "                try:\n",
    "                    url_element = job.find_element(By.CSS_SELECTOR, '[data-qa=\"serp-item__title\"]')\n",
    "                    job_url = url_element.get_attribute('href')\n",
    "                except Exception:\n",
    "                    job_url = \"Ссылка не доступна\"\n",
    "\n",
    "                try:\n",
    "                    experience_element = job.find_element(By.CSS_SELECTOR, '[data-qa=\"vacancy-serp__vacancy-work-experience\"]')\n",
    "                    experience = experience_element.text\n",
    "                except Exception:\n",
    "                    experience = \"Опыт не указан\"\n",
    "\n",
    "                job_data = [\n",
    "                    title,\n",
    "                    salary,\n",
    "                    company,\n",
    "                    location,\n",
    "                    experience,\n",
    "                    job_url,\n",
    "                    datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                ]\n",
    "                save_to_csv(job_data, csv_filename)\n",
    "\n",
    "                print(f\"\"\"\n",
    "                    {'='*70}\n",
    "                    Название: {title}\n",
    "                    Зп: {salary}\n",
    "                    Компания: {company}\n",
    "                    Локация: {location}\n",
    "                    Опыт: {experience}\n",
    "                    URL: {job_url}\n",
    "                    {'='*70}\n",
    "                    \"\"\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка парсинга вакансии: {e}\")\n",
    "\n",
    "def main():\n",
    "\n",
    "    # тут ничего интересного, просто создаем файл для сохранения данных\n",
    "    csv_filename = f'python_jobs_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.csv'\n",
    "    with open(csv_filename, 'w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['Название', 'Зп', 'Компания', 'Локация', 'Опыт', 'URL', 'Время'])\n",
    "\n",
    "    chrome_options = Options()  # Создаем объект настроек для хрома\n",
    "    \n",
    "    chrome_options.page_load_strategy = 'eager' # Устанавливаем стратегию загрузки страницы, нам это нужно чтобы не ждать загрузки всех элементов на странице\n",
    "\n",
    "    driver = webdriver.Chrome(options=chrome_options)   # Создаем сессию браузера\n",
    "    \n",
    "    driver.maximize_window()    # Разворачиваем окно браузера на весь экран, чтобы не было проблем с поиском элементов\n",
    "\n",
    "    try:\n",
    "        # тут все как в прошлом примере пока что\n",
    "        driver.get('https://hh.ru/')\n",
    "        \n",
    "        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.NAME, 'text')))\n",
    "\n",
    "        search_box = driver.find_element(By.NAME, 'text')\n",
    "        search_box.send_keys('Python')\n",
    "        search_box.send_keys(Keys.RETURN)\n",
    "\n",
    "        try:\n",
    "            WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.CLASS_NAME, 'bloko-modal-close-button')))\n",
    "            close_button = driver.find_element(By.CLASS_NAME, 'bloko-modal-close-button')\n",
    "            close_button.click()\n",
    "        except Exception:\n",
    "            print(\"Всплывающего окна нет или оно уже было закрыто\")\n",
    "\n",
    "        page_number = 1\n",
    "\n",
    "        page_number = 1\n",
    "        # тут начинается самое интересное\n",
    "        # мы будем переходить по страничкам и парсить их\n",
    "        while True:\n",
    "            print(f\"\\nПарсим страницу: {page_number}\")\n",
    "            \n",
    "            # ждем, пока не появится блок с вакансиями\n",
    "            WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.CLASS_NAME, 'vacancy-serp-content'))\n",
    "            )\n",
    "            \n",
    "            # ждем несколько секунд, чуть позже поймем зачем\n",
    "            time.sleep(random.uniform(2, 4))\n",
    "            \n",
    "            # парсим страницу\n",
    "            parse_page(driver, csv_filename)\n",
    "            \n",
    "            try:\n",
    "                # ждем пока появится блок с номерами страниц\n",
    "                pagination = WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.CSS_SELECTOR, '[data-qa=\"pager-block\"]'))\n",
    "                )\n",
    "\n",
    "                try:\n",
    "                    # находим кнопку с номером следующей страницы\n",
    "                    next_button = driver.find_element(By.CSS_SELECTOR, '[data-qa=\"pager-next\"]')\n",
    "                except:\n",
    "                    current_page_element = driver.find_element(By.CSS_SELECTOR, 'span[data-qa=\"pager-page\"]') # находим элемент с номером текущей страницы\n",
    "                    current_page = int(current_page_element.text) # находим номер текущей страницы\n",
    "                    next_page = str(current_page + 1) # находим номер следующей страницы\n",
    "                    \n",
    "                    page_elements = driver.find_elements(By.CSS_SELECTOR, '[data-qa=\"pager-page\"]') # находим все элементы с номерами страниц\n",
    "                    next_button = None\n",
    "                    \n",
    "                    # ищем кнопку с номером следующей страницы\n",
    "                    for element in page_elements:\n",
    "                        if element.text == next_page:\n",
    "                            next_button = element\n",
    "                            break\n",
    "                \n",
    "                # если кнопка с номером следующей страницы есть и она доступна\n",
    "                if next_button and next_button.is_displayed() and next_button.is_enabled():\n",
    "                    driver.execute_script(\"arguments[0].scrollIntoView(true);\", next_button) # скроллим до кнопки\n",
    "                    \n",
    "                    driver.execute_script(\"arguments[0].click();\", next_button) # кликаем по кнопке\n",
    "                    \n",
    "                    page_number += 1    # увеличиваем номер страницы на 1\n",
    "                    time.sleep(random.uniform(3, 5))    # ждем несколько секунд\n",
    "                else:\n",
    "                    print(\"\\nДошли до последней страницы\")\n",
    "                    break\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"\\nБольше нет страниц чтобы парсить: {str(e)}\")\n",
    "                break\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка: {e}\")\n",
    "\n",
    "    finally:\n",
    "        driver.quit()\n",
    "        print(f\"\\nИнформация была сохранения в {csv_filename}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Для чего же мы ждали несколько секунд и парились с скролингом странички?\n",
    "\n",
    "Дело в том, что на почти всех сайтах если такая шутка как robots.txt, куда и каким ботам можно ходить. Так вот, на hh.ru этот файл выглядит вот так:\n",
    "```txt\n",
    "User-agent: Yandex\n",
    "Disallow: /auth/*\n",
    "Disallow: /account/*\n",
    "Disallow: /area_switcher*\n",
    "Disallow: /search/vacancy/advanced\n",
    "Disallow: /search/resume/advanced\n",
    "Disallow: /rss/*\n",
    "Disallow: /admin/*\n",
    "Disallow: /article/22266\n",
    "Disallow: *?*\n",
    "Disallow: /article/compliance_hotline\n",
    "Disallow: /away\n",
    "\n",
    "User-agent: YandexDirect\n",
    "Allow: *?*\n",
    "\n",
    "User-agent: Googlebot\n",
    "Disallow: /auth/*\n",
    "Allow: /account/signup*\n",
    "Disallow: /account/*\n",
    "Disallow: /area_switcher*\n",
    "Disallow: /search/vacancy/advanced\n",
    "Disallow: /search/resume/advanced\n",
    "Disallow: /rss/*\n",
    "Disallow: /admin/*\n",
    "Disallow: /article/22266\n",
    "Disallow: *?*\n",
    "Disallow: /article/compliance_hotline\n",
    "Disallow: /away\n",
    "\n",
    "User-agent: AdsBot-Google\n",
    "Allow: /account/signup*\n",
    "\n",
    "User-agent: AdsBot-Google-Mobile\n",
    "Allow: /account/signup*\n",
    "\n",
    "User-agent: LCC\n",
    "Disallow: /\n",
    "\n",
    "User-agent: ltx71 - (http://ltx71.com/)\n",
    "Disallow: /\n",
    "\n",
    "User-agent: bingbot\n",
    "Crawl-delay: 60\n",
    "Disallow: /auth/*\n",
    "Disallow: /account/*\n",
    "Disallow: /area_switcher*\n",
    "Disallow: /search/vacancy/advanced\n",
    "Disallow: /search/resume/advanced\n",
    "Disallow: /rss/*\n",
    "Disallow: /admin/*\n",
    "Disallow: /article/22266\n",
    "Disallow: *?*\n",
    "Disallow: /article/compliance_hotline\n",
    "Disallow: /away\n",
    "\n",
    "User-agent: *\n",
    "Disallow: /auth/*\n",
    "Disallow: /account/*\n",
    "Disallow: /area_switcher*\n",
    "Disallow: /search/vacancy/advanced\n",
    "Disallow: /search/resume/advanced\n",
    "Disallow: /rss/*\n",
    "Disallow: /admin/*\n",
    "Disallow: /article/22266\n",
    "Disallow: *?*\n",
    "Disallow: /article/compliance_hotline\n",
    "Disallow: /away\n",
    "\n",
    "Host: https://hh.ru\n",
    "Sitemap: https://hh.ru/sitemap/main.xml\n",
    "```\n",
    "\n",
    "Нам интересен блок ```User-agent: *```, а именно строчка ```Disallow: *?*``` . Это говорит о том, что мы не можем передавать параметры в url, а это как раз таки то, что происходит, когда мы ищем какую-то вакансию. Хоть я и не слышал историй о том, что hh.ru активно банит ботов, мы все таки будем делать минимальный вид, что бот - реальный человек"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пример 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Нам не очень понравился результат по вакансиям разработчика со скилами парсинга, поэтому мы решаем открыть свой бизнем. Мы только что научились парсить странички, даже поняли, куда надо смотреть, чтобы нашего бота не забанили. Еще мы обладаем знаниями senior prompt инженера. Какая же идея нам подходит лучше всего??? Очевидно мы решили открыть ООО\"Чередной КриптоСтартап\". Идея заключается в том, что бы парсить основную информацию о монетках, а так же парсить твиты популярных личностей, потом спрашивать гпт куда пойдет цена монеты после таких заявлений, например, Дональда Трампа, и на основе этих данных торговать монетами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Что мы будем делать?\n",
    "- распарсим сайт yahoo.finance с информацией о монетах\n",
    "- распрасим твитер\n",
    "\n",
    "**Почему именно yahoo finance?**\\\n",
    "На самом деле потому что он позволяет ботам собирать любые данные, что позволяет не париться о бане нашего бота"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основной смысл этого примера - показать какие есть настройки браузера. В остальном тут нет ничего нового.\n",
    "\n",
    "Поскольку мы делаем крипто стартап, который потом будем класть на сервер, будем использовать сразу нужные для этого параметры\n",
    "\n",
    "**Настройки:**\n",
    "- ```--no-sandbox``` - отключает использование песочницы в гугле (штука для безопасности). Необходимо использовать, чтобы запускать скрипт как root или внутри Docker контейнера\n",
    "\n",
    "- ```--disable-dev-shm-usage``` - предотвращает проблемы с ограниченной общей памятью в Docker и помогает избежать ошибок из-за нехватки памяти\n",
    "\n",
    "- ```--window-size=1920,1080``` - устанавливает размеры окна браузера. Используем вместо ***driver.maximize_window()*** \n",
    "\n",
    "- ```--disable-gpu``` - отключает видеокарту при работе в --headless режиме\n",
    "\n",
    "- ```--disable-extensions``` - отключаем все расширения, которые могут подтащиться автоматически. Ускоряем работу браузера и делаем его чистым\n",
    "\n",
    "- ```eager``` - Ускоряем парсинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Начинаем парсить данные...\n",
      "Страница загружена\n",
      "Куки приняты\n",
      "Cryptocurrency: BTC-USD\n",
      "Price: 101344.945\n",
      "Market Cap: 2006066397184\n",
      "Volume: 86719709184\n",
      "----------------------------------------------------------------------\n",
      "Cryptocurrency: ETH-USD\n",
      "Price: 3818.8555\n",
      "Market Cap: 459961565184\n",
      "Volume: 37895823360\n",
      "----------------------------------------------------------------------\n",
      "Cryptocurrency: USDT-USD\n",
      "Price: 1.0008137\n",
      "Market Cap: 138731782144\n",
      "Volume: 191880003584\n",
      "----------------------------------------------------------------------\n",
      "Cryptocurrency: XRP-USD\n",
      "Price: 2.4206107\n",
      "Market Cap: 138258579456\n",
      "Volume: 19171753984\n",
      "----------------------------------------------------------------------\n",
      "Cryptocurrency: SOL-USD\n",
      "Price: 229.86247\n",
      "Market Cap: 109502300160\n",
      "Volume: 5844923904\n",
      "----------------------------------------------------------------------\n",
      "Cryptocurrency: BNB-USD\n",
      "Price: 707.2689\n",
      "Market Cap: 101852856320\n",
      "Volume: 2308736000\n",
      "----------------------------------------------------------------------\n",
      "Cryptocurrency: DOGE-USD\n",
      "Price: 0.41608918\n",
      "Market Cap: 61231648768\n",
      "Volume: 7223372288\n",
      "----------------------------------------------------------------------\n",
      "Cryptocurrency: USDC-USD\n",
      "Price: 0.99974924\n",
      "Market Cap: 41345716224\n",
      "Volume: 12385737728\n",
      "----------------------------------------------------------------------\n",
      "Cryptocurrency: ADA-USD\n",
      "Price: 1.0829241\n",
      "Market Cap: 38024421376\n",
      "Volume: 2428911872\n",
      "----------------------------------------------------------------------\n",
      "Cryptocurrency: STETH-USD\n",
      "Price: 3811.1265\n",
      "Market Cap: 37511155712\n",
      "Volume: 108297040\n",
      "----------------------------------------------------------------------\n",
      "Cryptocurrency: WTRX-USD\n",
      "Price: 0.28131467\n",
      "Market Cap: 24593344512\n",
      "Volume: 3514743\n",
      "----------------------------------------------------------------------\n",
      "Cryptocurrency: TRX-USD\n",
      "Price: 0.2810771\n",
      "Market Cap: 24243755008\n",
      "Volume: 1819528320\n",
      "----------------------------------------------------------------------\n",
      "Cryptocurrency: AVAX-USD\n",
      "Price: 47.88914\n",
      "Market Cap: 19619309568\n",
      "Volume: 927125056\n",
      "----------------------------------------------------------------------\n",
      "Cryptocurrency: SHIB-USD\n",
      "Price: 0.000029085286\n",
      "Market Cap: 17138667520\n",
      "Volume: 1837528960\n",
      "----------------------------------------------------------------------\n",
      "Cryptocurrency: WSTETH-USD\n",
      "Price: 4484.955\n",
      "Market Cap: 16334206976\n",
      "Volume: 45073188\n",
      "----------------------------------------------------------------------\n",
      "Cryptocurrency: TON11419-USD\n",
      "Price: 6.2961707\n",
      "Market Cap: 16060652544\n",
      "Volume: 354360288\n",
      "----------------------------------------------------------------------\n",
      "Cryptocurrency: LINK-USD\n",
      "Price: 23.888245\n",
      "Market Cap: 14974346240\n",
      "Volume: 1371676928\n",
      "----------------------------------------------------------------------\n",
      "Cryptocurrency: DOT-USD\n",
      "Price: 9.043372\n",
      "Market Cap: 13816523776\n",
      "Volume: 932759552\n",
      "----------------------------------------------------------------------\n",
      "Cryptocurrency: WBTC-USD\n",
      "Price: 100711.36\n",
      "Market Cap: 13720536064\n",
      "Volume: 694329280\n",
      "----------------------------------------------------------------------\n",
      "Cryptocurrency: XLM-USD\n",
      "Price: 0.4324922\n",
      "Market Cap: 13043814400\n",
      "Volume: 1286731520\n",
      "----------------------------------------------------------------------\n",
      "Cryptocurrency: WETH-USD\n",
      "Price: 3805.2278\n",
      "Market Cap: 12843852800\n",
      "Volume: 1434596352\n",
      "----------------------------------------------------------------------\n",
      "Cryptocurrency: SUI20947-USD\n",
      "Price: 4.3275094\n",
      "Market Cap: 12669475840\n",
      "Volume: 2127112192\n",
      "----------------------------------------------------------------------\n",
      "Cryptocurrency: HBAR-USD\n",
      "Price: 0.2983215\n",
      "Market Cap: 11404311552\n",
      "Volume: 1635978112\n",
      "----------------------------------------------------------------------\n",
      "Cryptocurrency: BCH-USD\n",
      "Price: 543.9388\n",
      "Market Cap: 10770266112\n",
      "Volume: 663033344\n",
      "----------------------------------------------------------------------\n",
      "Cryptocurrency: PEPE24478-USD\n",
      "Price: 0.000025203779\n",
      "Market Cap: 10602975232\n",
      "Volume: 5156206592\n",
      "----------------------------------------------------------------------\n",
      "Данные сохранены в: crypto_data.xlsx\n",
      "Скрипт успешно завершил работу!\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Настройки для Chrome WebDriver\n",
    "def setup_driver():\n",
    "    chrome_options = Options()\n",
    "    # chrome_options.add_argument(\"--headless\")  # Для наглядности пока что закоментем эту строчку\n",
    "    chrome_options.add_argument(\"--no-sandbox\") # Отключаем использование песочницы\n",
    "    chrome_options.add_argument(\"--disable-dev-shm-usage\")  # Отключаем использование /dev/shm\n",
    "    chrome_options.add_argument(\"--window-size=1920,1080\")  # Устанавливаем размер окна\n",
    "    \n",
    "    chrome_options.add_argument(\"--disable-gpu\")  # Отключаем использование GPU\n",
    "    chrome_options.add_argument(\"--disable-extensions\")  # Отключаем расширения\n",
    "    chrome_options.page_load_strategy = 'eager'  # Устанавливаем стратегию загрузки страницы\n",
    "\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    return driver\n",
    "\n",
    "def handle_cookie_consent(driver, wait):\n",
    "    try:\n",
    "        accept_button = wait.until(\n",
    "            EC.element_to_be_clickable((By.CSS_SELECTOR, \"button[class*='accept-all']\"))\n",
    "        )\n",
    "        accept_button.click()\n",
    "        return True\n",
    "    except (TimeoutException, NoSuchElementException) as e:\n",
    "        print(\"Cookie consent popup not found or already handled\")\n",
    "        return False\n",
    "\n",
    "def scrape_crypto_data():\n",
    "    url = \"https://finance.yahoo.com/crypto\"\n",
    "    driver = setup_driver()\n",
    "    wait = WebDriverWait(driver, 1)\n",
    "    crypto_data = []\n",
    "\n",
    "\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        print(\"Страница загружена\")\n",
    "\n",
    "        handle_cookie_consent(driver, wait)\n",
    "        print(\"Куки приняты\")\n",
    "\n",
    "        rows = driver.find_elements(By.CSS_SELECTOR, \"tr[class*='row']\")\n",
    "        for crypto_row in rows:\n",
    "            price_element = crypto_row.find_element(\n",
    "            By.CSS_SELECTOR, \n",
    "            \"fin-streamer[data-field='regularMarketPrice']\"\n",
    "        )\n",
    "            price = price_element.get_attribute('data-value')\n",
    "\n",
    "            name_element = crypto_row.find_element(\n",
    "                By.CSS_SELECTOR,\n",
    "                \"td[class*='cell']\"\n",
    "            )\n",
    "            name = name_element.text\n",
    "\n",
    "            capital_element = crypto_row.find_element(\n",
    "                By.CSS_SELECTOR, \n",
    "                \"fin-streamer[data-field='marketCap']\"\n",
    "            )\n",
    "\n",
    "            cap = capital_element.get_attribute('data-value')\n",
    "\n",
    "            volume_element = crypto_row.find_element(\n",
    "                By.CSS_SELECTOR, \n",
    "                \"fin-streamer[data-field='regularMarketVolume']\"\n",
    "            )\n",
    "\n",
    "            volume = volume_element.get_attribute('data-value')\n",
    "\n",
    "            print(f\"Cryptocurrency: {name}\")\n",
    "            print(f\"Price: {price}\")\n",
    "            print(f\"Market Cap: {cap}\")\n",
    "            print(f\"Volume: {volume}\")\n",
    "            print(\"-\" * 70)\n",
    "\n",
    "            crypto_data.append({\n",
    "                    'Name': name,\n",
    "                    'Price': float(price) if price else None,\n",
    "                    'Market_Cap': float(cap) if cap else None,\n",
    "                    'Volume': float(volume) if volume else None\n",
    "                })\n",
    "                \n",
    "\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "    return crypto_data\n",
    "\n",
    "def export_to_excel(crypto_data, filename='crypto_data.xlsx'):\n",
    "    if not crypto_data:\n",
    "        print(\"No data to export!\")\n",
    "        return\n",
    "        \n",
    "    df = pd.DataFrame(crypto_data)\n",
    "    \n",
    "    if 'Price' in df.columns:\n",
    "        df['Price'] = df['Price'].apply(lambda x: f\"${x:,.2f}\" if pd.notnull(x) else \"N/A\")\n",
    "    if 'Volume' in df.columns:\n",
    "        df['Volume'] = df['Volume'].apply(lambda x: f\"{x:,.2f}%\" if pd.notnull(x) else \"N/A\")\n",
    "    if 'Market_Cap' in df.columns:\n",
    "        df['Market_Cap'] = df['Market_Cap'].apply(lambda x: f\"${x:,.0f}\" if pd.notnull(x) else \"N/A\")\n",
    "    \n",
    "    # Export to Excel\n",
    "    df.to_excel(filename, index=False)\n",
    "    print(f\"Данные сохранены в: {filename}\")\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        print(\"Начинаем парсить данные...\")\n",
    "        crypto_data = scrape_crypto_data()\n",
    "        \n",
    "        if crypto_data:\n",
    "            export_to_excel(crypto_data)\n",
    "            print(\"Скрипт успешно завершил работу!\")\n",
    "        else:\n",
    "            print(\"Мы ничего не нашли\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Возникла ошибка: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🔥Ура мы узнали еще немного про selenium!🔥"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Парсинг твиттера (Настройка прокси)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы знаем, что твиттер очень хорошо отслеживает ботов, поэтому нам надо научиться использовать прокси сервера чтобы в случае бана мы могли продолжать парсить сайт."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предположим у нас уже есть настроенный в качестве proxy сервер.\n",
    "\n",
    "***Настройка сервера остается пытливому читателю в качестве тривиального упражнения***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим что наш сервер вообще работает и мы можем делать через него запросы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing HTTP connection...\n",
      "Status Code: 200\n",
      "Response: {\n",
      "  \"origin\": \"185.125.200.146\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "proxy_ip = \"185.125.200.146\"\n",
    "proxy_port = \"80\"\n",
    "username = \"proxy\"\n",
    "password = \"proxy123\"\n",
    "\n",
    "proxies = {\n",
    "    'http': f'http://{username}:{password}@{proxy_ip}:{proxy_port}',\n",
    "    'https': f'http://{username}:{password}@{proxy_ip}:{proxy_port}'\n",
    "}\n",
    "\n",
    "try:\n",
    "    print(\"Testing HTTP connection...\")\n",
    "    response = requests.get(\n",
    "        'http://httpbin.org/ip', \n",
    "        proxies=proxies,\n",
    "        timeout=10\n",
    "    )\n",
    "    print(f\"Status Code: {response.status_code}\")\n",
    "    print(f\"Response: {response.text}\")\n",
    "    \n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ура мы можем делать запросы**\n",
    "**Теперь надо понять как настроить прокси в selenium?**\n",
    "\n",
    "\n",
    "1) прописываем вот такое вот (этим все не заканчивается)\n",
    "```python\n",
    "chrome_options.add_argument(f'--proxy-server=http://{proxy_host}:{proxy_port}')\n",
    "```\n",
    "\n",
    "2) Прописываем manifest файл для хрома, чтобы он понимал как ему нужно работать\n",
    "3) создаем свое расширение\n",
    "4) загружаем расшираение в драйвер\n",
    "5) Ура наконец-то мы это все настроили! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-11 21:58:26,120 - INFO - ====== WebDriver manager ======\n",
      "2024-12-11 21:58:26,285 - INFO - Get LATEST chromedriver version for google-chrome\n",
      "2024-12-11 21:58:26,508 - INFO - Get LATEST chromedriver version for google-chrome\n",
      "2024-12-11 21:58:26,715 - INFO - Driver [/Users/alexeydubovitskiy/.wdm/drivers/chromedriver/mac64/131.0.6778.108/chromedriver-mac-arm64/chromedriver] found in cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accessing httpbin.org/ip through proxy...\n",
      "Response from httpbin.org/ip:\n",
      "{\n",
      "  \"origin\": \"185.125.200.146\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import os\n",
    "import zipfile\n",
    "import tempfile\n",
    "\n",
    "def setup_driver_with_proxy(proxy_host, proxy_port, proxy_username, proxy_password):\n",
    "    chrome_options = Options()\n",
    "    \n",
    "    # Добавляем прокси в настройки\n",
    "    proxy_string = f\"{proxy_username}:{proxy_password}@{proxy_host}:{proxy_port}\"\n",
    "    chrome_options.add_argument(f'--proxy-server=http://{proxy_host}:{proxy_port}')\n",
    "    \n",
    "    # Добавляем настройки для работы в headless режиме\n",
    "    chrome_options.add_argument('--no-sandbox')\n",
    "    chrome_options.add_argument('--headless=new')\n",
    "    chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "    \n",
    "    # Добавляем расширение для работы с прокси\n",
    "    manifest_json = \"\"\"\n",
    "    {\n",
    "        \"version\": \"1.0.0\",\n",
    "        \"manifest_version\": 2,\n",
    "        \"name\": \"Chrome Proxy\",\n",
    "        \"permissions\": [\n",
    "            \"proxy\",\n",
    "            \"tabs\",\n",
    "            \"unlimitedStorage\",\n",
    "            \"storage\",\n",
    "            \"<all_urls>\",\n",
    "            \"webRequest\",\n",
    "            \"webRequestBlocking\"\n",
    "        ],\n",
    "        \"background\": {\n",
    "            \"scripts\": [\"background.js\"]\n",
    "        },\n",
    "        \"minimum_chrome_version\":\"22.0.0\"\n",
    "    }\n",
    "    \"\"\"\n",
    "\n",
    "    background_js = \"\"\"\n",
    "    var config = {\n",
    "        mode: \"fixed_servers\",\n",
    "        rules: {\n",
    "            singleProxy: {\n",
    "                scheme: \"http\",\n",
    "                host: \"%s\",\n",
    "                port: parseInt(%s)\n",
    "            },\n",
    "            bypassList: [\"localhost\"]\n",
    "        }\n",
    "    };\n",
    "\n",
    "    chrome.proxy.settings.set({value: config, scope: \"regular\"}, function() {});\n",
    "\n",
    "    function callbackFn(details) {\n",
    "        return {\n",
    "            authCredentials: {\n",
    "                username: \"%s\",\n",
    "                password: \"%s\"\n",
    "            }\n",
    "        };\n",
    "    }\n",
    "\n",
    "    chrome.webRequest.onAuthRequired.addListener(\n",
    "        callbackFn,\n",
    "        {urls: [\"<all_urls>\"]},\n",
    "        ['blocking']\n",
    "    );\n",
    "    \"\"\" % (proxy_host, proxy_port, proxy_username, proxy_password)\n",
    "\n",
    "    # создаем временную директорию для расширения\n",
    "    extension_dir = tempfile.mkdtemp()\n",
    "    \n",
    "    # Создаем файлы для расширения\n",
    "    with open(os.path.join(extension_dir, \"manifest.json\"), \"w\") as f:\n",
    "        f.write(manifest_json)\n",
    "    with open(os.path.join(extension_dir, \"background.js\"), \"w\") as f:\n",
    "        f.write(background_js)\n",
    "    \n",
    "    # Создаем zip архив с расширением\n",
    "    zip_path = os.path.join(tempfile.mkdtemp(), \"proxy_auth.zip\")\n",
    "    with zipfile.ZipFile(zip_path, 'w') as zp:\n",
    "        for file in [\"manifest.json\", \"background.js\"]:\n",
    "            zp.write(os.path.join(extension_dir, file), file)\n",
    "    \n",
    "    # Добавляем расширение в настройки\n",
    "    chrome_options.add_extension(zip_path)\n",
    "    \n",
    "    # Устанавливаем драйвер\n",
    "    driver = webdriver.Chrome(\n",
    "        service=Service(ChromeDriverManager().install()),\n",
    "        options=chrome_options\n",
    "    )\n",
    "    \n",
    "    return driver # Ура мы настроили наш драйвер на работу через прокси\n",
    "\n",
    "def main():\n",
    "    # Конфигурация прокси\n",
    "    PROXY_HOST = \"185.125.200.146\"\n",
    "    PROXY_PORT = \"80\"\n",
    "    PROXY_USER = \"proxy\"\n",
    "    PROXY_PASS = \"proxy123\"\n",
    "    \n",
    "    try:\n",
    "        # создаем доавйер с настройками прокси\n",
    "        driver = setup_driver_with_proxy(PROXY_HOST, PROXY_PORT, PROXY_USER, PROXY_PASS)\n",
    "        \n",
    "        print(\"Получаем доступ к httpbin.org/ip через proxy...\")\n",
    "        driver.get(\"http://httpbin.org/ip\")\n",
    "        \n",
    "        # Ждем загрузки страницы\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "        body = wait.until(EC.presence_of_element_located((By.TAG_NAME, \"pre\")))\n",
    "        \n",
    "        print(\"Ответ от httpbin.org/ip:\")\n",
    "        print(body.text)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка: {str(e)}\")\n",
    "        \n",
    "    finally:\n",
    "        try:\n",
    "            driver.quit()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ура у нас действительно получилось настроить selenium с прокси\n",
    "\n",
    "**Теперь осталось распарсить твиттер...**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "robots.txt у x.com выглядит вот так:\n",
    "\n",
    "```txt\n",
    "# Google Search Engine Robot\n",
    "# ==========================\n",
    "User-agent: Googlebot\n",
    "\n",
    "Allow: /*?lang=\n",
    "Allow: /hashtag/*?src=\n",
    "Allow: /search?q=%23\n",
    "Allow: /i/api/\n",
    "Disallow: /search/realtime\n",
    "Disallow: /search/users\n",
    "Disallow: /search/*/grid\n",
    "\n",
    "Disallow: /*?\n",
    "Disallow: /*/followers\n",
    "Disallow: /*/following\n",
    "\n",
    "Disallow: /account/deactivated\n",
    "Disallow: /settings/deactivated\n",
    "\n",
    "Disallow: /[_0-9a-zA-Z]+/status/[0-9]+/likes\n",
    "Disallow: /[_0-9a-zA-Z]+/status/[0-9]+/retweets\n",
    "Disallow: /[_0-9a-zA-Z]+/likes\n",
    "Disallow: /[_0-9a-zA-Z]+/media \n",
    "Disallow: /[_0-9a-zA-Z]+/photo\n",
    "\n",
    "User-Agent: Google-Extended\n",
    "Disallow: *\n",
    "\n",
    "User-Agent: FacebookBot\n",
    "Disallow: *\n",
    "\n",
    "User-agent: facebookexternalhit\n",
    "Disallow: *\n",
    "\n",
    "User-agent: Discordbot\n",
    "Disallow: *\n",
    "\n",
    "User-agent: Bingbot\n",
    "Disallow: *\n",
    "\n",
    "# Every bot that might possibly read and respect this file\n",
    "# ========================================================\n",
    "User-agent: *\n",
    "Disallow: /\n",
    "\n",
    "\n",
    "# WHAT-4882 - Block indexing of links in notification emails. This applies to all bots.\n",
    "# =====================================================================================\n",
    "Disallow: /i/u\n",
    "Noindex: /i/u\n",
    "\n",
    "# Wait 1 second between successive requests. See ONBOARD-2698 for details.\n",
    "Crawl-delay: 1\n",
    "\n",
    "# Independent of user agent. Links in the sitemap are full URLs using https:// and need to match\n",
    "# the protocol of the sitemap.\n",
    "Sitemap: https://twitter.com/sitemap.xml\n",
    "```\n",
    "\n",
    "## ***Проще говоря тут запрещены все боты и их всех активно банят, поэтому нам надо быть аккуратными!***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-11 19:22:02,625 - INFO - ====== WebDriver manager ======\n",
      "2024-12-11 19:22:02,904 - INFO - Get LATEST chromedriver version for google-chrome\n",
      "2024-12-11 19:22:03,115 - INFO - Get LATEST chromedriver version for google-chrome\n",
      "2024-12-11 19:22:03,312 - INFO - Driver [/Users/alexeydubovitskiy/.wdm/drivers/chromedriver/mac64/131.0.6778.108/chromedriver-mac-arm64/chromedriver] found in cache\n",
      "2024-12-11 19:22:04,485 - INFO - Attempting to scrape https://x.com/realDonaldTrump\n",
      "2024-12-11 19:22:04,486 - INFO - Accessing https://x.com/realDonaldTrump\n",
      "2024-12-11 19:22:19,782 - INFO - Successfully extracted post text\n",
      "2024-12-11 19:22:19,783 - INFO - Successfully scraped https://x.com/realDonaldTrump\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Content from https://x.com/realDonaldTrump:\n",
      "Opposition fighters in Syria, in an unprecedented move, have totally taken over numerous cities, in a highly coordinated offensive, and are now on the outskirts of Damascus, obviously preparing to make a very big move toward taking out Assad. Russia, because they are so tied up\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, WebDriverException\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import random\n",
    "import time\n",
    "import logging\n",
    "import os\n",
    "import zipfile\n",
    "import tempfile\n",
    "\n",
    "# Прокси конфигурация как в прошлом примере\n",
    "class ProxyConfig:\n",
    "    def __init__(self, host, port, username, password):\n",
    "        self.host = host\n",
    "        self.port = port\n",
    "        self.username = username\n",
    "        self.password = password\n",
    "        \n",
    "    @property\n",
    "    def proxy_url(self):\n",
    "        return f\"{self.host}:{self.port}\"\n",
    "        \n",
    "    def create_proxy_extension(self):        \n",
    "        manifest_json = \"\"\"\n",
    "        {\n",
    "            \"version\": \"1.0.0\",\n",
    "            \"manifest_version\": 2,\n",
    "            \"name\": \"Chrome Proxy\",\n",
    "            \"permissions\": [\n",
    "                \"proxy\",\n",
    "                \"tabs\",\n",
    "                \"unlimitedStorage\",\n",
    "                \"storage\",\n",
    "                \"<all_urls>\",\n",
    "                \"webRequest\",\n",
    "                \"webRequestBlocking\"\n",
    "            ],\n",
    "            \"background\": {\n",
    "                \"scripts\": [\"background.js\"]\n",
    "            },\n",
    "            \"minimum_chrome_version\":\"22.0.0\"\n",
    "        }\n",
    "        \"\"\"\n",
    "\n",
    "        background_js = \"\"\"\n",
    "        var config = {\n",
    "            mode: \"fixed_servers\",\n",
    "            rules: {\n",
    "                singleProxy: {\n",
    "                    scheme: \"http\",\n",
    "                    host: \"%s\",\n",
    "                    port: parseInt(%s)\n",
    "                },\n",
    "                bypassList: [\"localhost\"]\n",
    "            }\n",
    "        };\n",
    "\n",
    "        chrome.proxy.settings.set({value: config, scope: \"regular\"}, function() {});\n",
    "\n",
    "        function callbackFn(details) {\n",
    "            return {\n",
    "                authCredentials: {\n",
    "                    username: \"%s\",\n",
    "                    password: \"%s\"\n",
    "                }\n",
    "            };\n",
    "        }\n",
    "\n",
    "        chrome.webRequest.onAuthRequired.addListener(\n",
    "            callbackFn,\n",
    "            {urls: [\"<all_urls>\"]},\n",
    "            ['blocking']\n",
    "        );\n",
    "        \"\"\" % (self.host, self.port, self.username, self.password)\n",
    "\n",
    "        extension_dir = tempfile.mkdtemp()\n",
    "        \n",
    "        with open(os.path.join(extension_dir, \"manifest.json\"), \"w\") as f:\n",
    "            f.write(manifest_json)\n",
    "        with open(os.path.join(extension_dir, \"background.js\"), \"w\") as f:\n",
    "            f.write(background_js)\n",
    "        \n",
    "        zip_path = os.path.join(tempfile.mkdtemp(), \"proxy_auth.zip\")\n",
    "        with zipfile.ZipFile(zip_path, 'w') as zp:\n",
    "            for file in [\"manifest.json\", \"background.js\"]:\n",
    "                zp.write(os.path.join(extension_dir, file), file)\n",
    "        \n",
    "        return zip_path\n",
    "\n",
    "class WebScraper:\n",
    "    def __init__(self, proxy_config):\n",
    "        self.proxy_config = proxy_config\n",
    "        self.driver = None\n",
    "        \n",
    "        # добавляем логирование чтоб было жить проще\n",
    "        logging.basicConfig(\n",
    "            level=logging.INFO,\n",
    "            format='%(asctime)s - %(levelname)s - %(message)s'\n",
    "        )\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "    \n",
    "    def setup_driver(self):\n",
    "        chrome_options = Options()\n",
    "        \n",
    "        # Добавляем расширение прокси\n",
    "        proxy_extension = self.proxy_config.create_proxy_extension()\n",
    "        chrome_options.add_extension(proxy_extension)\n",
    "        \n",
    "        # Добавляем настройки для работы в headless режиме\n",
    "        chrome_options.add_argument('--no-sandbox')\n",
    "        chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "        # chrome_options.add_argument('--headless=new')\n",
    "        \n",
    "        # Создаем драйвер\n",
    "        driver = webdriver.Chrome(\n",
    "            service=Service(ChromeDriverManager().install()),\n",
    "            options=chrome_options\n",
    "        )\n",
    "        \n",
    "        return driver\n",
    "    \n",
    "    def start_session(self):\n",
    "        self.driver = self.setup_driver()\n",
    "        self.driver.set_page_load_timeout(30) # Устанавливаем таймаут загрузки страницы\n",
    "    \n",
    "    def close_session(self):\n",
    "        if self.driver:\n",
    "            self.driver.quit()\n",
    "            self.driver = None\n",
    "    \n",
    "    def scrape_url(self, url):\n",
    "        try:\n",
    "            self.logger.info(f\"Accessing {url}\")\n",
    "            self.driver.get(url)\n",
    "            \n",
    "            \n",
    "            WebDriverWait(self.driver, 20).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, '[data-testid=\"tweet\"]'))\n",
    "            )\n",
    "            \n",
    "            # Находим первый твит (самый новый)\n",
    "            post_element = WebDriverWait(self.driver, 10).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, '[data-testid=\"tweet\"] [data-testid=\"tweetText\"]'))\n",
    "            )\n",
    "            \n",
    "            # Достаем текст твита\n",
    "            post_text = post_element.text\n",
    "            \n",
    "            self.logger.info(\"Ура мы достали текст\")\n",
    "            return post_text\n",
    "                \n",
    "        except (TimeoutException, WebDriverException) as e:\n",
    "            self.logger.error(f\"Ошибка парсинга {url}: {str(e)}\")\n",
    "            return None\n",
    "        \n",
    "    def scrape_urls(self, urls, max_retries=1):\n",
    "        results = {}\n",
    "        \n",
    "        for url in urls:\n",
    "            retries = 0\n",
    "            success = False\n",
    "            \n",
    "            while retries < max_retries and not success:\n",
    "                try:\n",
    "                    # Начинаем новую сессию для каждой попытки\n",
    "                    self.close_session()\n",
    "                    self.start_session()\n",
    "                    \n",
    "                    self.logger.info(f\"Attempting to scrape {url}\")\n",
    "                    result = self.scrape_url(url)\n",
    "                    \n",
    "                    if result:\n",
    "                        results[url] = result\n",
    "                        success = True\n",
    "                        self.logger.info(f\"Успешно спарсили {url}\")\n",
    "                    else:\n",
    "                        retries += 1\n",
    "                        self.logger.warning(f\"Неудача на попытке {retries} при парсинге {url}\")\n",
    "                \n",
    "                except Exception as e:\n",
    "                    retries += 1\n",
    "                    self.logger.error(f\"Ошибка: {str(e)}\")\n",
    "                \n",
    "                # Добавляем задержку\n",
    "                time.sleep(random.uniform(2, 4))\n",
    "        \n",
    "        return results\n",
    "\n",
    "# Пример использования\n",
    "if __name__ == \"__main__\":\n",
    "    proxy_config = ProxyConfig(\n",
    "        host=\"185.125.200.146\",\n",
    "        port=\"80\",\n",
    "        username=\"proxy\",\n",
    "        password=\"proxy123\"\n",
    "    )\n",
    "    \n",
    "    # Какие ссылки хотим спарсить\n",
    "    urls_to_scrape = [\n",
    "        \"https://x.com/realDonaldTrump\",\n",
    "    ]\n",
    "    \n",
    "    scraper = WebScraper(proxy_config)\n",
    "    \n",
    "    try:\n",
    "        results = scraper.scrape_urls(urls_to_scrape)\n",
    "        \n",
    "        # Выводим результаты\n",
    "        for url, content in results.items():\n",
    "            print(f\"\\nContent from {url}:\")\n",
    "            print(content)\n",
    "            \n",
    "    finally:\n",
    "        scraper.close_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ура у нас действитльно получилось спарсить твитер. А еще мы научились использовать прокси сервера при работе с selenium!!\n",
    "\n",
    "**Все что нам осталось перед запуском криптостартапа - это купить 40 000 серверов, добавить случайный выбор сервера при парсинге твитера, поставить eager режим, настроить запросы к GPT и написать торогового бота. В целом занятие на 1 вечер для senior prompt инженера, но это остается в качестве упражнения по желанию для читателя.**\n",
    "\n",
    "В итоге мы научились использовать прокси сервер в selenium, что позволит мень задумываться о банах при парсинге. УРА!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Выводы\n",
    "\n",
    "В результате мы научились пользоваться библиотекой **selenium** для парсинга данных. Посмотрели на разные примеры, от самого простого, до использования прокси серверов для запросов. Это позволяет нам уверенно пользоваться этой библиотекой!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
